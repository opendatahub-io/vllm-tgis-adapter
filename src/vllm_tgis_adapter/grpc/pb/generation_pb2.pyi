"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file

Internal service interface for FMaaS completions
"""

import builtins
import collections.abc
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import sys
import typing

if sys.version_info >= (3, 10):
    import typing as typing_extensions
else:
    import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

class _DecodingMethod:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _DecodingMethodEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_DecodingMethod.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    GREEDY: _DecodingMethod.ValueType  # 0
    SAMPLE: _DecodingMethod.ValueType  # 1

class DecodingMethod(_DecodingMethod, metaclass=_DecodingMethodEnumTypeWrapper):
    """============================================================================================================
    Generation API
    """

GREEDY: DecodingMethod.ValueType  # 0
SAMPLE: DecodingMethod.ValueType  # 1
global___DecodingMethod = DecodingMethod

class _StopReason:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _StopReasonEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_StopReason.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    NOT_FINISHED: _StopReason.ValueType  # 0
    """Possibly more tokens to be streamed"""
    MAX_TOKENS: _StopReason.ValueType  # 1
    """Maximum requested tokens reached"""
    EOS_TOKEN: _StopReason.ValueType  # 2
    """End-of-sequence token encountered"""
    CANCELLED: _StopReason.ValueType  # 3
    """Request cancelled by client"""
    TIME_LIMIT: _StopReason.ValueType  # 4
    """Time limit reached"""
    STOP_SEQUENCE: _StopReason.ValueType  # 5
    """Stop sequence encountered"""
    TOKEN_LIMIT: _StopReason.ValueType  # 6
    """Total token limit reached"""
    ERROR: _StopReason.ValueType  # 7
    """Decoding error"""

class StopReason(_StopReason, metaclass=_StopReasonEnumTypeWrapper): ...

NOT_FINISHED: StopReason.ValueType  # 0
"""Possibly more tokens to be streamed"""
MAX_TOKENS: StopReason.ValueType  # 1
"""Maximum requested tokens reached"""
EOS_TOKEN: StopReason.ValueType  # 2
"""End-of-sequence token encountered"""
CANCELLED: StopReason.ValueType  # 3
"""Request cancelled by client"""
TIME_LIMIT: StopReason.ValueType  # 4
"""Time limit reached"""
STOP_SEQUENCE: StopReason.ValueType  # 5
"""Stop sequence encountered"""
TOKEN_LIMIT: StopReason.ValueType  # 6
"""Total token limit reached"""
ERROR: StopReason.ValueType  # 7
"""Decoding error"""
global___StopReason = StopReason

@typing.final
class BatchedGenerationRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    MODEL_ID_FIELD_NUMBER: builtins.int
    PREFIX_ID_FIELD_NUMBER: builtins.int
    ADAPTER_ID_FIELD_NUMBER: builtins.int
    REQUESTS_FIELD_NUMBER: builtins.int
    PARAMS_FIELD_NUMBER: builtins.int
    model_id: builtins.str
    prefix_id: builtins.str
    """Deprecated in favor of adapter_id"""
    adapter_id: builtins.str
    @property
    def requests(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___GenerationRequest]: ...
    @property
    def params(self) -> global___Parameters: ...
    def __init__(
        self,
        *,
        model_id: builtins.str = ...,
        prefix_id: builtins.str | None = ...,
        adapter_id: builtins.str | None = ...,
        requests: collections.abc.Iterable[global___GenerationRequest] | None = ...,
        params: global___Parameters | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["_adapter_id", b"_adapter_id", "_prefix_id", b"_prefix_id", "adapter_id", b"adapter_id", "params", b"params", "prefix_id", b"prefix_id"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["_adapter_id", b"_adapter_id", "_prefix_id", b"_prefix_id", "adapter_id", b"adapter_id", "model_id", b"model_id", "params", b"params", "prefix_id", b"prefix_id", "requests", b"requests"]) -> None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_adapter_id", b"_adapter_id"]) -> typing.Literal["adapter_id"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_prefix_id", b"_prefix_id"]) -> typing.Literal["prefix_id"] | None: ...

global___BatchedGenerationRequest = BatchedGenerationRequest

@typing.final
class SingleGenerationRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    MODEL_ID_FIELD_NUMBER: builtins.int
    PREFIX_ID_FIELD_NUMBER: builtins.int
    ADAPTER_ID_FIELD_NUMBER: builtins.int
    REQUEST_FIELD_NUMBER: builtins.int
    PARAMS_FIELD_NUMBER: builtins.int
    model_id: builtins.str
    prefix_id: builtins.str
    """Deprecated in favor of adapter_id"""
    adapter_id: builtins.str
    @property
    def request(self) -> global___GenerationRequest: ...
    @property
    def params(self) -> global___Parameters: ...
    def __init__(
        self,
        *,
        model_id: builtins.str = ...,
        prefix_id: builtins.str | None = ...,
        adapter_id: builtins.str | None = ...,
        request: global___GenerationRequest | None = ...,
        params: global___Parameters | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["_adapter_id", b"_adapter_id", "_prefix_id", b"_prefix_id", "adapter_id", b"adapter_id", "params", b"params", "prefix_id", b"prefix_id", "request", b"request"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["_adapter_id", b"_adapter_id", "_prefix_id", b"_prefix_id", "adapter_id", b"adapter_id", "model_id", b"model_id", "params", b"params", "prefix_id", b"prefix_id", "request", b"request"]) -> None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_adapter_id", b"_adapter_id"]) -> typing.Literal["adapter_id"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_prefix_id", b"_prefix_id"]) -> typing.Literal["prefix_id"] | None: ...

global___SingleGenerationRequest = SingleGenerationRequest

@typing.final
class BatchedGenerationResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    RESPONSES_FIELD_NUMBER: builtins.int
    @property
    def responses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___GenerationResponse]: ...
    def __init__(
        self,
        *,
        responses: collections.abc.Iterable[global___GenerationResponse] | None = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["responses", b"responses"]) -> None: ...

global___BatchedGenerationResponse = BatchedGenerationResponse

@typing.final
class GenerationRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    TEXT_FIELD_NUMBER: builtins.int
    text: builtins.str
    def __init__(
        self,
        *,
        text: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["text", b"text"]) -> None: ...

global___GenerationRequest = GenerationRequest

@typing.final
class GenerationResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    INPUT_TOKEN_COUNT_FIELD_NUMBER: builtins.int
    GENERATED_TOKEN_COUNT_FIELD_NUMBER: builtins.int
    TEXT_FIELD_NUMBER: builtins.int
    STOP_REASON_FIELD_NUMBER: builtins.int
    STOP_SEQUENCE_FIELD_NUMBER: builtins.int
    SEED_FIELD_NUMBER: builtins.int
    TOKENS_FIELD_NUMBER: builtins.int
    INPUT_TOKENS_FIELD_NUMBER: builtins.int
    input_token_count: builtins.int
    generated_token_count: builtins.int
    text: builtins.str
    stop_reason: global___StopReason.ValueType
    stop_sequence: builtins.str
    """The stop sequence encountered, iff stop_reason == STOP_SEQUENCE"""
    seed: builtins.int
    """Random seed used, not applicable for greedy requests"""
    @property
    def tokens(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___TokenInfo]:
        """Individual generated tokens and associated details, if requested"""

    @property
    def input_tokens(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___TokenInfo]:
        """Input tokens and associated details, if requested"""

    def __init__(
        self,
        *,
        input_token_count: builtins.int = ...,
        generated_token_count: builtins.int = ...,
        text: builtins.str = ...,
        stop_reason: global___StopReason.ValueType = ...,
        stop_sequence: builtins.str = ...,
        seed: builtins.int = ...,
        tokens: collections.abc.Iterable[global___TokenInfo] | None = ...,
        input_tokens: collections.abc.Iterable[global___TokenInfo] | None = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["generated_token_count", b"generated_token_count", "input_token_count", b"input_token_count", "input_tokens", b"input_tokens", "seed", b"seed", "stop_reason", b"stop_reason", "stop_sequence", b"stop_sequence", "text", b"text", "tokens", b"tokens"]) -> None: ...

global___GenerationResponse = GenerationResponse

@typing.final
class Parameters(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    METHOD_FIELD_NUMBER: builtins.int
    SAMPLING_FIELD_NUMBER: builtins.int
    STOPPING_FIELD_NUMBER: builtins.int
    RESPONSE_FIELD_NUMBER: builtins.int
    DECODING_FIELD_NUMBER: builtins.int
    TRUNCATE_INPUT_TOKENS_FIELD_NUMBER: builtins.int
    method: global___DecodingMethod.ValueType
    """The high level decoding approach"""
    truncate_input_tokens: builtins.int
    """Truncate to this many input tokens. Can be used to avoid requests
    failing due to input being longer than configured limits.
    Zero means don't truncate.
    """
    @property
    def sampling(self) -> global___SamplingParameters:
        """Parameters related to sampling, applicable only when method == SAMPLING"""

    @property
    def stopping(self) -> global___StoppingCriteria:
        """Parameters controlling when generation should stop"""

    @property
    def response(self) -> global___ResponseOptions:
        """Flags to control what is returned in the response"""

    @property
    def decoding(self) -> global___DecodingParameters:
        """Parameters for conditionally penalizing/boosting
        candidate tokens during decoding
        """

    def __init__(
        self,
        *,
        method: global___DecodingMethod.ValueType = ...,
        sampling: global___SamplingParameters | None = ...,
        stopping: global___StoppingCriteria | None = ...,
        response: global___ResponseOptions | None = ...,
        decoding: global___DecodingParameters | None = ...,
        truncate_input_tokens: builtins.int = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["decoding", b"decoding", "response", b"response", "sampling", b"sampling", "stopping", b"stopping"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["decoding", b"decoding", "method", b"method", "response", b"response", "sampling", b"sampling", "stopping", b"stopping", "truncate_input_tokens", b"truncate_input_tokens"]) -> None: ...

global___Parameters = Parameters

@typing.final
class DecodingParameters(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    class _ResponseFormat:
        ValueType = typing.NewType("ValueType", builtins.int)
        V: typing_extensions.TypeAlias = ValueType

    class _ResponseFormatEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[DecodingParameters._ResponseFormat.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
        TEXT: DecodingParameters._ResponseFormat.ValueType  # 0
        """Plain text, no constraints"""
        JSON: DecodingParameters._ResponseFormat.ValueType  # 1
        """Valid json"""

    class ResponseFormat(_ResponseFormat, metaclass=_ResponseFormatEnumTypeWrapper): ...
    TEXT: DecodingParameters.ResponseFormat.ValueType  # 0
    """Plain text, no constraints"""
    JSON: DecodingParameters.ResponseFormat.ValueType  # 1
    """Valid json"""

    @typing.final
    class LengthPenalty(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        START_INDEX_FIELD_NUMBER: builtins.int
        DECAY_FACTOR_FIELD_NUMBER: builtins.int
        start_index: builtins.int
        """Start the decay after this number of tokens have been generated"""
        decay_factor: builtins.float
        """Factor of exponential decay"""
        def __init__(
            self,
            *,
            start_index: builtins.int = ...,
            decay_factor: builtins.float = ...,
        ) -> None: ...
        def ClearField(self, field_name: typing.Literal["decay_factor", b"decay_factor", "start_index", b"start_index"]) -> None: ...

    @typing.final
    class StringChoices(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        CHOICES_FIELD_NUMBER: builtins.int
        @property
        def choices(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
        def __init__(
            self,
            *,
            choices: collections.abc.Iterable[builtins.str] | None = ...,
        ) -> None: ...
        def ClearField(self, field_name: typing.Literal["choices", b"choices"]) -> None: ...

    REPETITION_PENALTY_FIELD_NUMBER: builtins.int
    LENGTH_PENALTY_FIELD_NUMBER: builtins.int
    FORMAT_FIELD_NUMBER: builtins.int
    JSON_SCHEMA_FIELD_NUMBER: builtins.int
    REGEX_FIELD_NUMBER: builtins.int
    CHOICE_FIELD_NUMBER: builtins.int
    GRAMMAR_FIELD_NUMBER: builtins.int
    repetition_penalty: builtins.float
    """Default (0.0) means no penalty (equivalent to 1.0)
    1.2 is a recommended value
    """
    format: global___DecodingParameters.ResponseFormat.ValueType
    """Output will be in the specified format"""
    json_schema: builtins.str
    """Output will follow the provided JSON schema"""
    regex: builtins.str
    """Output will follow the provided regex pattern"""
    grammar: builtins.str
    """Output will follow the provided context free grammar"""
    @property
    def length_penalty(self) -> global___DecodingParameters.LengthPenalty:
        """Exponentially increases the score of the EOS token
        once start_index tokens have been generated
        """

    @property
    def choice(self) -> global___DecodingParameters.StringChoices:
        """Output will be exactly one of the specified choices"""

    def __init__(
        self,
        *,
        repetition_penalty: builtins.float = ...,
        length_penalty: global___DecodingParameters.LengthPenalty | None = ...,
        format: global___DecodingParameters.ResponseFormat.ValueType = ...,
        json_schema: builtins.str = ...,
        regex: builtins.str = ...,
        choice: global___DecodingParameters.StringChoices | None = ...,
        grammar: builtins.str = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["_length_penalty", b"_length_penalty", "choice", b"choice", "format", b"format", "grammar", b"grammar", "guided", b"guided", "json_schema", b"json_schema", "length_penalty", b"length_penalty", "regex", b"regex"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["_length_penalty", b"_length_penalty", "choice", b"choice", "format", b"format", "grammar", b"grammar", "guided", b"guided", "json_schema", b"json_schema", "length_penalty", b"length_penalty", "regex", b"regex", "repetition_penalty", b"repetition_penalty"]) -> None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_length_penalty", b"_length_penalty"]) -> typing.Literal["length_penalty"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["guided", b"guided"]) -> typing.Literal["format", "json_schema", "regex", "choice", "grammar"] | None: ...

global___DecodingParameters = DecodingParameters

@typing.final
class SamplingParameters(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    TEMPERATURE_FIELD_NUMBER: builtins.int
    TOP_K_FIELD_NUMBER: builtins.int
    TOP_P_FIELD_NUMBER: builtins.int
    TYPICAL_P_FIELD_NUMBER: builtins.int
    SEED_FIELD_NUMBER: builtins.int
    temperature: builtins.float
    """Unset will default to 1.0
    0.0 is equivalent to greedy decoding
    """
    top_k: builtins.int
    """Default (0) means disabled"""
    top_p: builtins.float
    """Default (0) means disabled (equivalent to 1.0)"""
    typical_p: builtins.float
    """Default (0) means disabled (equivalent to 1.0)"""
    seed: builtins.int
    def __init__(
        self,
        *,
        temperature: builtins.float | None = ...,
        top_k: builtins.int = ...,
        top_p: builtins.float = ...,
        typical_p: builtins.float = ...,
        seed: builtins.int | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["_seed", b"_seed", "_temperature", b"_temperature", "seed", b"seed", "temperature", b"temperature"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["_seed", b"_seed", "_temperature", b"_temperature", "seed", b"seed", "temperature", b"temperature", "top_k", b"top_k", "top_p", b"top_p", "typical_p", b"typical_p"]) -> None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_seed", b"_seed"]) -> typing.Literal["seed"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_temperature", b"_temperature"]) -> typing.Literal["temperature"] | None: ...

global___SamplingParameters = SamplingParameters

@typing.final
class StoppingCriteria(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    MAX_NEW_TOKENS_FIELD_NUMBER: builtins.int
    MIN_NEW_TOKENS_FIELD_NUMBER: builtins.int
    TIME_LIMIT_MILLIS_FIELD_NUMBER: builtins.int
    STOP_SEQUENCES_FIELD_NUMBER: builtins.int
    INCLUDE_STOP_SEQUENCE_FIELD_NUMBER: builtins.int
    max_new_tokens: builtins.int
    """Default (0) is currently 20"""
    min_new_tokens: builtins.int
    """Default (0) means no minimum"""
    time_limit_millis: builtins.int
    """Default (0) means no time limit"""
    include_stop_sequence: builtins.bool
    """If not specified, default behavior depends on server setting"""
    @property
    def stop_sequences(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
    def __init__(
        self,
        *,
        max_new_tokens: builtins.int = ...,
        min_new_tokens: builtins.int = ...,
        time_limit_millis: builtins.int = ...,
        stop_sequences: collections.abc.Iterable[builtins.str] | None = ...,
        include_stop_sequence: builtins.bool | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["_include_stop_sequence", b"_include_stop_sequence", "include_stop_sequence", b"include_stop_sequence"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["_include_stop_sequence", b"_include_stop_sequence", "include_stop_sequence", b"include_stop_sequence", "max_new_tokens", b"max_new_tokens", "min_new_tokens", b"min_new_tokens", "stop_sequences", b"stop_sequences", "time_limit_millis", b"time_limit_millis"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["_include_stop_sequence", b"_include_stop_sequence"]) -> typing.Literal["include_stop_sequence"] | None: ...

global___StoppingCriteria = StoppingCriteria

@typing.final
class ResponseOptions(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    INPUT_TEXT_FIELD_NUMBER: builtins.int
    GENERATED_TOKENS_FIELD_NUMBER: builtins.int
    INPUT_TOKENS_FIELD_NUMBER: builtins.int
    TOKEN_LOGPROBS_FIELD_NUMBER: builtins.int
    TOKEN_RANKS_FIELD_NUMBER: builtins.int
    TOP_N_TOKENS_FIELD_NUMBER: builtins.int
    input_text: builtins.bool
    """Include input text"""
    generated_tokens: builtins.bool
    """Include list of individual generated tokens
    "Extra" token information is included based on the other flags below
    """
    input_tokens: builtins.bool
    """Include list of input tokens
    "Extra" token information is included based on the other flags here,
    but only for decoder-only models
    """
    token_logprobs: builtins.bool
    """Include logprob for each returned token
    Applicable only if generated_tokens == true and/or input_tokens == true
    """
    token_ranks: builtins.bool
    """Include rank of each returned token
    Applicable only if generated_tokens == true and/or input_tokens == true
    """
    top_n_tokens: builtins.int
    """Include top n candidate tokens at the position of each returned token
    The maximum value permitted is 5, but more may be returned if there is a tie
    for nth place.
    Applicable only if generated_tokens == true and/or input_tokens == true
    """
    def __init__(
        self,
        *,
        input_text: builtins.bool = ...,
        generated_tokens: builtins.bool = ...,
        input_tokens: builtins.bool = ...,
        token_logprobs: builtins.bool = ...,
        token_ranks: builtins.bool = ...,
        top_n_tokens: builtins.int = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["generated_tokens", b"generated_tokens", "input_text", b"input_text", "input_tokens", b"input_tokens", "token_logprobs", b"token_logprobs", "token_ranks", b"token_ranks", "top_n_tokens", b"top_n_tokens"]) -> None: ...

global___ResponseOptions = ResponseOptions

@typing.final
class TokenInfo(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    @typing.final
    class TopToken(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        TEXT_FIELD_NUMBER: builtins.int
        LOGPROB_FIELD_NUMBER: builtins.int
        text: builtins.str
        """uint32 id = 1;  // TBD"""
        logprob: builtins.float
        def __init__(
            self,
            *,
            text: builtins.str = ...,
            logprob: builtins.float = ...,
        ) -> None: ...
        def ClearField(self, field_name: typing.Literal["logprob", b"logprob", "text", b"text"]) -> None: ...

    TEXT_FIELD_NUMBER: builtins.int
    LOGPROB_FIELD_NUMBER: builtins.int
    RANK_FIELD_NUMBER: builtins.int
    TOP_TOKENS_FIELD_NUMBER: builtins.int
    text: builtins.str
    """uint32 id = 1;  // TBD"""
    logprob: builtins.float
    """The logprob (log of normalized probability), if requested"""
    rank: builtins.int
    """One-based rank relative to other tokens, if requested"""
    @property
    def top_tokens(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___TokenInfo.TopToken]:
        """Top N candidate tokens at this position, if requested
        May or may not include this token
        """

    def __init__(
        self,
        *,
        text: builtins.str = ...,
        logprob: builtins.float = ...,
        rank: builtins.int = ...,
        top_tokens: collections.abc.Iterable[global___TokenInfo.TopToken] | None = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["logprob", b"logprob", "rank", b"rank", "text", b"text", "top_tokens", b"top_tokens"]) -> None: ...

global___TokenInfo = TokenInfo

@typing.final
class BatchedTokenizeRequest(google.protobuf.message.Message):
    """============================================================================================================
    Tokenization API
    """

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    MODEL_ID_FIELD_NUMBER: builtins.int
    PREFIX_ID_FIELD_NUMBER: builtins.int
    ADAPTER_ID_FIELD_NUMBER: builtins.int
    REQUESTS_FIELD_NUMBER: builtins.int
    RETURN_TOKENS_FIELD_NUMBER: builtins.int
    RETURN_OFFSETS_FIELD_NUMBER: builtins.int
    TRUNCATE_INPUT_TOKENS_FIELD_NUMBER: builtins.int
    model_id: builtins.str
    prefix_id: builtins.str
    """Deprecated in favor of adapter_id"""
    adapter_id: builtins.str
    return_tokens: builtins.bool
    return_offsets: builtins.bool
    truncate_input_tokens: builtins.int
    """Zero means don't truncate."""
    @property
    def requests(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___TokenizeRequest]: ...
    def __init__(
        self,
        *,
        model_id: builtins.str = ...,
        prefix_id: builtins.str | None = ...,
        adapter_id: builtins.str | None = ...,
        requests: collections.abc.Iterable[global___TokenizeRequest] | None = ...,
        return_tokens: builtins.bool = ...,
        return_offsets: builtins.bool = ...,
        truncate_input_tokens: builtins.int = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["_adapter_id", b"_adapter_id", "_prefix_id", b"_prefix_id", "adapter_id", b"adapter_id", "prefix_id", b"prefix_id"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["_adapter_id", b"_adapter_id", "_prefix_id", b"_prefix_id", "adapter_id", b"adapter_id", "model_id", b"model_id", "prefix_id", b"prefix_id", "requests", b"requests", "return_offsets", b"return_offsets", "return_tokens", b"return_tokens", "truncate_input_tokens", b"truncate_input_tokens"]) -> None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_adapter_id", b"_adapter_id"]) -> typing.Literal["adapter_id"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_prefix_id", b"_prefix_id"]) -> typing.Literal["prefix_id"] | None: ...

global___BatchedTokenizeRequest = BatchedTokenizeRequest

@typing.final
class BatchedTokenizeResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    RESPONSES_FIELD_NUMBER: builtins.int
    @property
    def responses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___TokenizeResponse]: ...
    def __init__(
        self,
        *,
        responses: collections.abc.Iterable[global___TokenizeResponse] | None = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["responses", b"responses"]) -> None: ...

global___BatchedTokenizeResponse = BatchedTokenizeResponse

@typing.final
class TokenizeRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    TEXT_FIELD_NUMBER: builtins.int
    text: builtins.str
    def __init__(
        self,
        *,
        text: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["text", b"text"]) -> None: ...

global___TokenizeRequest = TokenizeRequest

@typing.final
class TokenizeResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    @typing.final
    class Offset(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        START_FIELD_NUMBER: builtins.int
        END_FIELD_NUMBER: builtins.int
        start: builtins.int
        end: builtins.int
        def __init__(
            self,
            *,
            start: builtins.int = ...,
            end: builtins.int = ...,
        ) -> None: ...
        def ClearField(self, field_name: typing.Literal["end", b"end", "start", b"start"]) -> None: ...

    TOKEN_COUNT_FIELD_NUMBER: builtins.int
    TOKENS_FIELD_NUMBER: builtins.int
    OFFSETS_FIELD_NUMBER: builtins.int
    token_count: builtins.int
    @property
    def tokens(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
        """if return_tokens = true"""

    @property
    def offsets(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___TokenizeResponse.Offset]:
        """if return_tokens = true"""

    def __init__(
        self,
        *,
        token_count: builtins.int = ...,
        tokens: collections.abc.Iterable[builtins.str] | None = ...,
        offsets: collections.abc.Iterable[global___TokenizeResponse.Offset] | None = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["offsets", b"offsets", "token_count", b"token_count", "tokens", b"tokens"]) -> None: ...

global___TokenizeResponse = TokenizeResponse

@typing.final
class ModelInfoRequest(google.protobuf.message.Message):
    """============================================================================================================
    Model Info API
    """

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    MODEL_ID_FIELD_NUMBER: builtins.int
    model_id: builtins.str
    def __init__(
        self,
        *,
        model_id: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["model_id", b"model_id"]) -> None: ...

global___ModelInfoRequest = ModelInfoRequest

@typing.final
class ModelInfoResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    class _ModelKind:
        ValueType = typing.NewType("ValueType", builtins.int)
        V: typing_extensions.TypeAlias = ValueType

    class _ModelKindEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[ModelInfoResponse._ModelKind.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
        DECODER_ONLY: ModelInfoResponse._ModelKind.ValueType  # 0
        ENCODER_DECODER: ModelInfoResponse._ModelKind.ValueType  # 1

    class ModelKind(_ModelKind, metaclass=_ModelKindEnumTypeWrapper): ...
    DECODER_ONLY: ModelInfoResponse.ModelKind.ValueType  # 0
    ENCODER_DECODER: ModelInfoResponse.ModelKind.ValueType  # 1

    MODEL_KIND_FIELD_NUMBER: builtins.int
    MAX_SEQUENCE_LENGTH_FIELD_NUMBER: builtins.int
    MAX_NEW_TOKENS_FIELD_NUMBER: builtins.int
    model_kind: global___ModelInfoResponse.ModelKind.ValueType
    max_sequence_length: builtins.int
    max_new_tokens: builtins.int
    def __init__(
        self,
        *,
        model_kind: global___ModelInfoResponse.ModelKind.ValueType = ...,
        max_sequence_length: builtins.int = ...,
        max_new_tokens: builtins.int = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["max_new_tokens", b"max_new_tokens", "max_sequence_length", b"max_sequence_length", "model_kind", b"model_kind"]) -> None: ...

global___ModelInfoResponse = ModelInfoResponse
